{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "W szczególności zwróć uwagę, że usupełniłeś wszystkie miejsca `YOUR CODE HERE`, `WPISZ TWÓJ KOD TUTAJ`, \"YOUR ANSWER HERE\" lub \"WPISZ TWOJĄ ODPOWIEDŹ TUTAJ\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaawansowane Przetwarzanie Języka Naturalnego\n",
    "# Laboratorium 2\n",
    "\n",
    "Pobierz zbiór danych Amazon \"Musical Instruments\" z [tej](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz) strony internetowej, a następnie wczytaj go poniższym kodem. Zwróć uwagę na wymaganą lokalizację pliku, tj. dwa katalogi wyżej - wynika to ze struktury plików w sprawdzarce, przepraszam za niedogodność.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "\n",
    "x_text = []\n",
    "y = []\n",
    "with open('../../Musical_Instruments_5.json') as file:\n",
    "  for line in file:\n",
    "    data = json.loads(line)\n",
    "    x_text.append(data['reviewText'].lower().strip())\n",
    "    y.append(int(data['overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - przygotowanie danych\n",
    "W załadowanych listach `x_text` oraz `y` znajdują się odpowiednio teksty kolejnych opinii oraz oznaczenia klas. Klasą w tym wypadku jest liczba gwiazdek (ocena) produktu towarzysząca opinii. Zadanie klasyfikacji polega na przewidzeniu oceny na podstawie opinii pozostawionej w portalu.\n",
    "\n",
    "Aby zmniejszyć wymagania obliczeniowe do dalszych eksperymentów, ograniczymy zbiór danych jedynie do pierwszego tysiąca opinii.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = x_text[:1000]\n",
    "y = y[:1000]\n",
    "train_end_idx = int(0.9 * len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedną z użytecznych operacji przygotowania tekstu do konstrukcji klasyfikatora jest zastąpienie poszczególnych tokenów ich indeksami. Chociaż w praktyce ten proces często następuje dopiero po szeregu etapów przetwarzania tekstu takich jak tokenizacja, lematyzacja czy stemming - w tym ćwiczeniu wyodrębnimy tokeny rozdzielając tekst znakiem spacji.\n",
    "\n",
    "Klasyfikator powinien obsługiwać także słowa, które nie występowały w zbiorze uczącym. Podstawową techniką obsługi takich słów jest wprowadzenie specjalnego tokenu UNK, obsługującego nieznane słowa. W tym celu usuwa się ze zbioru danych pewną liczbę najrzadszych słów i zastępuje się je tokenami UNK.\n",
    "\n",
    "Zbuduj słownik `w2i` mapujący tokeny na kolejne indeksy tj. liczby naturalne. Pomiń tokeny występujące w zbiorze uczącym 5 lub mniej razy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f866dd9918a27f9ba2f31ef62a061fa1",
     "grade": false,
     "grade_id": "cell-87edb8b6e5279a0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterable, TypeVar\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "#Przypisz indeks tokenowi UNK\n",
    "UNK = w2i[\"<unk>\"]\n",
    "\n",
    "T = TypeVar('T')\n",
    "def flatten(items: Iterable[Iterable[T]]) -> Iterable[T]:\n",
    "  return [item for sublist in items for item in sublist]\n",
    "\n",
    "words: list[str] = flatten(map(lambda sentence: sentence.split(\" \"), x_text))\n",
    "word_counts = Counter(words)\n",
    "words_above_5 = [word for word, count in word_counts.items() if count > 5]\n",
    "\n",
    "for word in words_above_5: w2i[word]\n",
    "\n",
    "n_words = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b1000affcd1be506cad1e3a22a63cf1",
     "grade": true,
     "grade_id": "cell-59701c5db1041735",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389\n"
     ]
    }
   ],
   "source": [
    "print(n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zbudowaniu słownika `w2i`, przekonwertujmy nasz zbiór danych z listy słów na listę indeksów słów. Od razu podzielimy zbiór na część uczącą i część testową, a także przekonwertujemy klasy na indeksy klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domyślną wartością słownika jest UNK,\n",
    "#   chociaż w2i będzie zawierał wpisy do wszystkich słów to nowym tokenom będzie przypisywał indeks UNK\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "# mapuj klasy na indeksy klas\n",
    "class2i = defaultdict(lambda: len(class2i))\n",
    "\n",
    "def read_dataset(start_idx, end_idx):\n",
    "  for i, text in enumerate(x_text[start_idx:end_idx]):\n",
    "    yield ([w2i[x] for x in text.split(\" \")], class2i[y[i]])\n",
    "\n",
    "train = list(read_dataset(0, train_end_idx))\n",
    "dev = list(read_dataset(train_end_idx, len(y)))\n",
    "n_class = len(class2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389 5\n"
     ]
    }
   ],
   "source": [
    "print(n_words, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - pierwszy model klasyfikacji tekstu w PyTorch\n",
    "Podstawową strukturą danych w PyTorch jest tensor, na którym możesz wykonywać analogiczne operacje jak na macierzach `numpy`. Podstawową metodą stworzenia tensora jest wywołanie konstruktora `torch.tensor` na liście liczb. Istnieją także inne konstruktory tensorów, analogiczne do `numpy`. Można też na nich operować za pomocą standardowych operatorów, indeksowania, i odpowiedników innych funkcji znanych z `numpy`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0.2007, 0.0427, 0.7757],\n",
      "        [0.4818, 0.1617, 0.8729],\n",
      "        [0.9221, 0.2080, 0.2761]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1, 2, 3]))\n",
    "print(torch.rand((3, 3)))\n",
    "print(torch.ones((3, 3)))\n",
    "print(2 * torch.ones((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dlaczego więc korzystamy z PyTorch, a nie z biblioteki `numpy` skoro tensory wydają się mieć analogiczną funkcjonalność do poznanych uprzednio macierzy? Powodów jest oczywiście wiele, m.in. możliwość przeniesienia obliczeń na kartę graficzną (technologia CUDA), ale z punktu widzenia naszego ćwiczenia kluczowa jest funkcjonalność automatycznego liczenia gradientów. W przypadku konstrukcji sieci neuronowej czy modelu liniowego, w PyTorch nie jest konieczne samodzielne wyprowadzanie i implementowanie gradientu, gdyż biblioteka zrobi to za nas automatycznie.\n",
    "\n",
    "Wyznaczanie gradientów odbywa się za pomocą algorytmu wstecznej propagacji, który ma dwie fazy: *forward* i *backward*. Faza *forward* polega na policzeniu wyniku funkcji, a faza *backward* wyznacza gradienty wszystkich jej parametrów.\n",
    "\n",
    "W celu poznania tej funkcjonalności policzymy pochodne cząstkowe prostej funkcji kwadratowej:\n",
    "$$result = x_1^2 + x_2^2+ x_3^2$$\n",
    "której pochodne cząstkowe mają postać $2x_i$.\n",
    "\n",
    "Rozpocznijmy implementacje tej funkcji od stworzenia 3-elementowego wektora zmiennych `x`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak pewnie zauważyłeś, w konstruktorze użyliśmy dodatkowego parametru `requires_grad`. Domyślnie wykonanie operacji na dowolnym tensorze nie traktuje się jako części fazy `forward`, gdyż nie do wszystkich tensorów użytych w kodzie będziemy potrzebować wartości pochodnych. Aby zasygnalizować, że dla danej zmiennej konieczne jest zapisywanie informacji o wykonywanych na niej operacjach, należy ustawić wartość jej parametru `requires_grad` na `True`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejdźmy do policzenia wartości wyżej zdefiniowanej funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (x ** 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensory posiadają parametr `.grad`, który przechowuje informacje o wyznaczonym gradiencie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tej chwili, pomimo obliczenia wartości zmiennej `result`, wartość gradientu nie jest policzona, gdyż nie poinformowaliśmy biblioteki o zakończeniu fazy `forward` i konieczności wykonania fazy `backward`. Możemy to zrobić poprzez wykonanie funkcji `backward()` na obliczonej wartości funkcji (funkcję tę można wywołać tylko na skalarnym wyniku!).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2., 4., 6.])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróć uwagę, że wektor `x.grad`, zgodnie z naszymi oczekiwaniami, zawiera wartości pochodnej cząstkowej tj. `2x`. Spróbujmy jeszcze raz, licząc pochodną po logarytmie z `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = torch.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[89], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mresult2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\2023-anlp\\venv\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\2023-anlp\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "result2.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety operacja się nie powiodła. Przed wykonaniem kolejnej fazy *backward* należy - upraszczając - wykonać fazę *forward*. Nasze poprzednie operacje konstruowały fazę *forward* od parametrów `x` aż do zmiennej z wynikiem, jednakże przy wykonaniu fazy *backward* została zwolniona pamięć przechowująca informacje o kolejno wykonywanych operacjach na tych zmiennych (graf obliczeń). Kolejna operacja została wykonana bezpośrednio na tensorze `result`, konstruując fazę *forward* od `result` do `result2`, jednak zabrakło grafu obliczeń od parametrów `x`.\n",
    "\n",
    "Uruchomienie poniższego kodu, z operacjami rozpoczynającymi się od `x`, zakończy się obliczeniem gradientu z sukcesem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1429, 4.2857, 6.4286])\n"
     ]
    }
   ],
   "source": [
    "result = (x ** 2).sum()\n",
    "result2 = torch.log(result)\n",
    "result2.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy poprawność uzyskanego wyniku. Zmienna $result= 1^2+2^2+3^2=14$, a pochodna z logarytmu naturalnego to $\\frac{1}{x}$. W związku z tym:\n",
    "$$\\frac{\\partial }{\\partial x_1} \\log result = \\frac{1}{result} \\cdot \\frac{\\partial }{\\partial x_1} result = \\frac{1}{result} 2x_1 $$\n",
    "Przy naszych wartościach $x$ równa się to $\\frac{1}{14}\\cdot 2 = 0,1428$. Łatwo zauważyć, że wynik znajdujący się w tensorze `x.grad` jest błędny, a konkretnie za duży o 2 jednostki.\n",
    "\n",
    "Stało się tak dlatego, że gradient z kolejnych faz `backward` jest akumulowany w parametrze `.grad` (poprzednia wartość policzonej pochodnej cząstkowej wynosiła właśnie 2). Takie zachowanie biblioteki może być bardzo użyteczne w sytuacji gdy chcemy w zmiennej zagregować gradienty funkcji celu liczonych na kolejno przetwarzanych instancjach lub przy treningu modelu z wieloma funkcjami celu; tutaj jednak doprowadziło to do błędnego wyniku. Z tego powodu bardzo ważne jest pamiętanie o wyzerowaniu wartości gradientów przed przystąpieniem do kolejnych obliczeń.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0.])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1429, 0.2857, 0.4286])\n"
     ]
    }
   ],
   "source": [
    "result = (x ** 2).sum()\n",
    "result2 = torch.log(result)\n",
    "result2.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróć uwagę na konwencję biblioteki PyTorch - jeśli nazwa funkcji zakończona jest podkreślnikiem to taka operacja jest wykonywana `in-place`. (np. `x.add(5)` - `x` nadal ma stałą wartość, `x.add_(5)` wartość `x` zwiększono o 5).\n",
    "\n",
    "Zaimplementujmy podstawowy algorytm uczący w PyTorch. Będzie to prosta sieć neuronowa składająca się z:\n",
    "- macierzy zanurzeń $C$, przetwarzającej indeksy słów na odpowiednie reprezentacje wektorowe, \n",
    "- operacji uśredniania tych zanurzeń do jednego zanurzenia (average pooling over time) \n",
    "- oraz jednej warstwy liniowej (softmax) zwracającej wynik.\n",
    "\n",
    "Algorytmem uczącym będzie SGD optymalizujące entropię krzyżową, czyli dla kolejnych instancji uczących będziemy wykonywać:\n",
    "$$parametry = parametry - \\eta \\nabla f\\_celu$$\n",
    "Implementacja ta będzie wyjątkowo prosta, gdyż gradient funkcji celu ($\\nabla f\\_celu$) zostanie obliczony automatycznie przez PyTorch. Ponadto entropia krzyżowa jest już zaimplementowana w PyTorch `F.cross_entropy(logits, target)`. Zwróć uwagę, że argumentem tej funkcji są wartości logitów (nie trzeba implementować funkcji softmax przetwarzającej wartości logitów na prawdopodobieństwa).\n",
    "\n",
    "**UWAGA** W implementacji nie należy używać gotowych implementacji SGD czy warstw sieci neuronowych w PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem w implementacji będzie zaimplementowanie samego modelu. Należy zainicjalizować macierz $C$ przechowującą w wierszach zanurzenia dla kolejnych słów (liczba słów to `n_words`, wymiarowość zanurzenia określ na 20) oraz macierz $W$ przechowującą parametry warstwy liniowej, zwracającej wartości logitów dla każdej z klas (liczba klas to `n_class`). Macierz $W$ w dodatkowej kolumnie powinna też przechowywać wartości wyrazów wolnych (bias). Wartości zainicjalizuj losowo `torch.rand`. Pamiętaj, że dla tych macierzy będziesz potrzebował wyznaczyć potem wartości gradientów.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "134cf7cd8660133b178caff1ca2fcdfc",
     "grade": false,
     "grade_id": "cell-9ba79ce47d0c6a5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 20\n",
    "C = torch.rand((n_words, EMBEDDING_SIZE), requires_grad=True)\n",
    "W = torch.rand((n_class, EMBEDDING_SIZE + 1), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "084514b8fbf6ffa4f784b5b398bd3624",
     "grade": true,
     "grade_id": "cell-b3436825d33d5941",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję `simple_model`, której argumentem będzie instancja testowa (jest to więc lista indeksów słów występujących w tekście), a na której wyjściu będzie wektor `n_class`-elementowy zawierający obliczone wartości logitów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "280f8962c6b7f20c718a51b6ecc294a4",
     "grade": false,
     "grade_id": "cell-e2668a9abacbc78a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def simple_model(x):\n",
    "  doc_embedding = torch.mean(C[x], dim=0)\n",
    "  # Skonkatenowanie 1 z uzyskaną reprezentacją (bias)\n",
    "  doc_with_bias = torch.cat([torch.ones(1), doc_embedding])\n",
    "  # Obliczenie wartości logitów (tj. warstwa liniowa)\n",
    "  return W @ doc_with_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj algorytm SGD w poniższej pętli. Pętla ta iteruje po zbiorze uczącym oraz dla każdej instancji oblicza wartość funkcji celu. Twoje zadania:\n",
    "- Policz gradienty (faza *backward*)\n",
    "- Zaimplementuj aktualizacje $W$ i $C$ wg. wzoru na SGD. Operacje modyfikujące $W$ i $C$ musisz wykonać w środku klauzuli `with torch.no_grad():`, aby nie śledzić z tych operacji gradientów.\n",
    "- Pamiętaj o wyczyszczeniu gradientów (zarówno w $W$ jak i $C$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80acc452845b941b086f5aa582f26d87",
     "grade": false,
     "grade_id": "cell-aeedd0f5183bd781",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: avg. train loss=1.1350\n",
      "iter 1: avg. train loss=0.9683\n",
      "iter 2: avg. train loss=0.9510\n",
      "iter 3: avg. train loss=0.9056\n",
      "iter 4: avg. train loss=0.8673\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "epochs = 5\n",
    "# prędkość uczenia\n",
    "eta = 0.5\n",
    "\n",
    "for i in range(epochs):\n",
    "  random.shuffle(train)\n",
    "  train_loss = 0.0\n",
    "  for (words, tag) in train:\n",
    "    pred = simple_model(words)\n",
    "    loss = F.cross_entropy(pred.reshape(1, -1), torch.tensor(tag).reshape(1))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "      train_loss += loss\n",
    "      W -= eta * W.grad\n",
    "      W.grad.zero_()\n",
    "      C -= eta * C.grad\n",
    "      C.grad.zero_()\n",
    "\n",
    "  print(f\"iter {i!r}: avg. train loss={train_loss / len(train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ćwiczenia**\n",
    "- Dlaczego w bibliotekach do głębokiego uczenia maszynowego, takich jak PyTorch, implementuje się funkcje entropii krzyżowej tak, aby przyjmowała na wejście wartości logitów zamiast prawdopodobieństw z softmax?\n",
    "- Na wykładzie pokazywaliśmy warstwę zanurzeń jako warstwę mnożącą macierz $C$ przez wektor \"1 z n\", można ją jednak także zaimplementować jako operację odczytu odpowiedniego wiersza z macierzy. Jakie są wady i zalety obu tych sposobów implementacji?\n",
    "\n",
    "Odpowiedź na pierwszą kropkę umieść poniżej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5158398dc380a8a01088a617375d8f4c",
     "grade": true,
     "grade_id": "cell-c685493684bda3e3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "- Tak jest szybciej obliczeniowo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 - wykorzystanie nn.Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch jako biblioteka do głębokiego uczenia maszynowego oferuje nam kilka udogodnień w implementowaniu modeli uczących się, aby jeszcze bardziej uprościć ich implementację. Większość z tych udogodnień związanych z jest z reprezentowaniem modeli uczących się jako obiektów dziedziczących po `torch.nn.Module`. W obiekcie takim powinniśmy zaimplementować co najmniej konstruktor, inicjalizujący parametry modelu ($W$ i $C$), oraz funkcję `forward` obliczającą wynik modelu (we wcześniejszym zadaniu nazywaliśmy ją `simple_model`). Ponadto moduł `torch.nn` oferuje gotowe implementacje zarówno warstwy liniowej jak i warstwy zanurzeń.\n",
    "\n",
    "Przeanalizuj poniższą implementację modelu z poprzedniego zadania.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "  def __init__(self, n_words, emb_size, n_class):\n",
    "    super(SimpleModel, self).__init__()\n",
    "    self.embedding = torch.nn.Embedding(n_words, emb_size)\n",
    "    self.linear = torch.nn.Linear(in_features=emb_size, out_features=n_class, bias=True)\n",
    "    torch.nn.init.uniform_(self.embedding.weight, -0.25, 0.25)\n",
    "    torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "  def forward(self, words):\n",
    "    emb = self.embedding(words)\n",
    "    h = emb.mean(dim=0)\n",
    "    h = torch.reshape(h, (1, -1))\n",
    "    out = self.linear(h)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oprócz tego, że uzyskaliśmy elegancki obiekt reprezentujący nasz model, nie wydaje się by powyższa implementacja była krótsza czy prostsza od tej, którą uzyskaliśmy w poprzednim zadaniu bez dobrodziejstw `nn.Module`. Co zatem zyskaliśmy?\n",
    "\n",
    "Przy implementacji modeli z dużą liczbą warstw, szczególnie uciążliwe byłoby implementowanie kolejnych linijek kodu zerujących gradienty wszystkich macierzy wag, oraz wykonywanie na nich kroków algorytmu SGD. W naszej implementacji każda macierz parametrów to dwie linijki kodu! Jednak modele dziedziczące po `torch.nn.Module` i stworzone poprzez dedykowane warstwy neuronowe posiadają gotową funkcję `parameters()` zwracającą kolejne macierze parametrów modelu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2470,  0.1388,  0.1190,  ..., -0.1174,  0.2328, -0.1112],\n",
      "        [ 0.0867, -0.0493,  0.2327,  ...,  0.2399,  0.1282,  0.2321],\n",
      "        [ 0.1459,  0.1198,  0.1962,  ...,  0.1707,  0.0035,  0.1114],\n",
      "        ...,\n",
      "        [ 0.2148,  0.1403, -0.1995,  ...,  0.2258, -0.2428, -0.0004],\n",
      "        [ 0.1914,  0.1553, -0.1501,  ...,  0.1793, -0.1802, -0.1464],\n",
      "        [ 0.0330, -0.1476,  0.1698,  ...,  0.0819, -0.2070,  0.0312]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2631,  0.4753,  0.4408,  0.3415,  0.4402,  0.3595, -0.4329, -0.3152,\n",
      "         -0.2523,  0.3000,  0.2884, -0.2490,  0.2577,  0.3266, -0.3069,  0.3628,\n",
      "         -0.4171, -0.4767, -0.1492,  0.0640],\n",
      "        [-0.2712, -0.2150,  0.4466, -0.4002,  0.0379, -0.0282,  0.0164,  0.0613,\n",
      "         -0.2983, -0.0180, -0.1717, -0.2341, -0.3825,  0.0577, -0.1914, -0.1872,\n",
      "          0.0017, -0.4259,  0.4308,  0.2323],\n",
      "        [ 0.4528, -0.0149, -0.4617, -0.3858,  0.2678, -0.4160,  0.3752, -0.3620,\n",
      "          0.2681,  0.4497, -0.4061,  0.0201,  0.1487, -0.3567,  0.2408,  0.2469,\n",
      "         -0.0391,  0.3966, -0.1487,  0.2160],\n",
      "        [ 0.2108,  0.4248, -0.2844,  0.3554,  0.3184,  0.2998,  0.4527, -0.4212,\n",
      "          0.4315,  0.4519,  0.1543, -0.3509, -0.1868, -0.3075,  0.2468,  0.1069,\n",
      "         -0.0745, -0.4793, -0.4280, -0.2908],\n",
      "        [-0.0810,  0.1973,  0.0783,  0.0230,  0.0804,  0.1231, -0.3424,  0.2399,\n",
      "         -0.3592, -0.4855,  0.0187,  0.2889,  0.0143,  0.3357,  0.1232, -0.2285,\n",
      "         -0.2900,  0.1120,  0.0147, -0.4706]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0494, -0.1393,  0.0040, -0.0488, -0.0956], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(n_words, EMBEDDING_SIZE, n_class)\n",
    "print([i for i in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to niezwykle wygodne, bo implementacja algorytmu SGD może przeiterować po tej liście parametrów i dla każdej z nich wykonać aktualizację ich wartości. Fakt, że taka lista jest tworzona automatycznie pozbawia nas ryzyka, że zwyczajnie o którejś macierzy parametrów czy wektorze wyrazów wolnych najzwyczajniej zapomnimy.\n",
    "\n",
    "Podobnie można zaimplementować pętlę zerującą gradienty wszystkich parametrów. Modele oferują nawet gotową taką funkcję `model.zero_grad()`, która iteruje po parametrach zerując ich gradienty. \n",
    "\n",
    "Zmodyfikuj implementację SGD z poprzedniego zadania, tak aby wykorzystywała `zero_grad()` i `parameters()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5f2f3a6cb7d7b2d2e34e63a2b54004b",
     "grade": false,
     "grade_id": "cell-87d2dfc0c801725a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: avg. train loss=0.4290\n",
      "iter 1: avg. train loss=0.4124\n",
      "iter 2: avg. train loss=0.3818\n",
      "iter 3: avg. train loss=0.4097\n",
      "iter 4: avg. train loss=0.3527\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "# prędkość uczenia\n",
    "eta = 0.5\n",
    "\n",
    "for i in range(epochs):\n",
    "  random.shuffle(train)\n",
    "\n",
    "  train_loss = 0.0\n",
    "  for (words, tag) in train:\n",
    "    pred = model(torch.tensor(words))\n",
    "    loss = F.cross_entropy(pred.reshape(1, -1), torch.tensor(tag).reshape(1))\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      train_loss += loss\n",
    "      for param in model.parameters():\n",
    "        param -= eta * param.grad\n",
    "    model.zero_grad()\n",
    "  print(f\"iter {i!r}: avg. train loss={train_loss / len(train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo moduł `torch.nn` oferuje także od razu zaimplementowane optymalizatory, w tym SGD. W konstruktorze optymalizatora należy podać listę optymalizowanych przez niego parametrów, a następnie wywołać na nim procedurę `step()` wykonującą krok algorytmu optymalizacyjnego tj. aktualizację wartości zmiennych przy użyciu gradientu. W tej sytuacji nie musisz się martwić o umieszczanie kodu zmieniającego parametry w `with torch.no_grad()` - optymalizator sam to zrobi! Optymalizator również oferuje funkcję `zero_grad()`, zerującą gradienty zmiennych wskazanych do optymalizacji.\n",
    "\n",
    "Zmodyfikuj kod z poprzedniego zadania, tak aby wykorzystywał optymalizator SGD zaimplementowany w `torch.optim`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92b92a0626a6c533b3b61aa2e6c18ddd",
     "grade": false,
     "grade_id": "cell-5588a40beb11d256",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: avg. train loss=0.2806\n",
      "iter 1: avg. train loss=0.2760\n",
      "iter 2: avg. train loss=0.2631\n",
      "iter 3: avg. train loss=0.2653\n",
      "iter 4: avg. train loss=0.2328\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 5\n",
    "# prędkość uczenia\n",
    "eta = 0.5\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "for i in range(epochs):\n",
    "  random.shuffle(train)\n",
    "\n",
    "  train_loss = 0.0\n",
    "  for (words, tag) in train:\n",
    "    pred = model(torch.tensor(words))\n",
    "    loss = F.cross_entropy(pred.reshape(1, -1), torch.tensor(tag).reshape(1))\n",
    "    loss.backward()\n",
    "\n",
    "    train_loss += loss\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  print(f\"iter {i!r}: avg. train loss={train_loss / len(train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ćwiczenia**\n",
    "- Przeanalizuj dokładnie powyższy kod i przechodząc linia po linii, wyjaśnij co one robią z punktu widzenia treningu modelu.\n",
    "- Zastanów się jak wyglądałaby Twoja własna implementacja klasy `optim.SGD`.\n",
    "- Prześledź jeszcze raz implementację modelu neuronowego - pewnie w niedługim czasie będziesz implementował znacznie bardziej skomplikowane modele, tym bardziej warto je dobrze prześledzić!\n",
    "- Czym różni się zaimplementowana architektura od głębokiej sieci uśredniającej?\n",
    "- Na wykładzie korzystaliśmy z macierzy zanurzeń w modelach języka. Tutaj warstwa zanurzeń pojawiła się bezpośrednio w modelu klasyfikacji. Czy w uzyskanych w ten sposób zanurzeniach (zakładając dobry dobór hiperparamerów, dodanie regularyzacji itd.) zaobserwowalibyśmy podobne zależności jak te uzyskane za pomocą modelu języka? Jeśli nie, obserwacji jakich zależności między słowami spodziewałbyś się w tej reprezentacji? Skąd biorą się różnice?\n",
    "\n",
    "Odpowiedź na ostatnią kropkę umieść poniżej.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "731e0439a761d52c3124060a972eaf31",
     "grade": true,
     "grade_id": "cell-50c2ecade40bcd7f",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "W modelach językowych wykorzystywaliśmy ngramy i uproszczonych łańcuchów Markov'a, które często odwzorowały wygląd słów współwystępujących, antonimy i zależności wokół słów, czy inne proste cechy, z zanurzeniem możemy uchwycić elementy ważne do klasyfikacji tekstu, niekoniecznie zależności znaczeniowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73080ad0900acee85ddd2dd6ff52a07d",
     "grade": false,
     "grade_id": "cell-a81ef968001b7310",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Zadanie 4\n",
    "Wykorzystując wiedzę z poprzedniego zadania zaimplementuj prostą architekturę splotową do klasyfikacji tekstu i wytrenuj ją. Do jej wykonania może być przydatna klasa `torch.nn.Conv1d` i funkcja `torch.nn.ReLU` (zapoznaj się z ich dokumentacją w Internecie). Jako funkcji redukcji użyj funkcji maksimum (over time).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(1389, 20)\n",
      "  (convolution): Conv1d(20, 32, kernel_size=(1,), stride=(1,))\n",
      "  (linear): Linear(in_features=32, out_features=5, bias=True)\n",
      ")\n",
      "iter 0: avg. train loss=1.0153\n",
      "iter 1: avg. train loss=0.9609\n",
      "iter 2: avg. train loss=0.9229\n",
      "iter 3: avg. train loss=0.9049\n",
      "iter 4: avg. train loss=0.8787\n",
      "iter 5: avg. train loss=0.8679\n",
      "iter 6: avg. train loss=0.8309\n",
      "iter 7: avg. train loss=0.8201\n",
      "iter 8: avg. train loss=0.7878\n",
      "iter 9: avg. train loss=0.7728\n",
      "iter 10: avg. train loss=0.7444\n",
      "iter 11: avg. train loss=0.6973\n",
      "iter 12: avg. train loss=0.7173\n",
      "iter 13: avg. train loss=0.6905\n",
      "iter 14: avg. train loss=0.6710\n"
     ]
    }
   ],
   "source": [
    "def pipe(fns, initial):\n",
    "  result = initial\n",
    "  for fn in fns: result = fn(result)\n",
    "  return result\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self, nwords, emb_size, num_filters, window_size, ntags):\n",
    "    super().__init__()\n",
    "    self.embedding = torch.nn.Embedding(nwords, emb_size)\n",
    "    self.reshape_embeddings = lambda x: x.reshape(1, emb_size, -1)\n",
    "    self.convolution = torch.nn.Conv1d(emb_size, num_filters, window_size)\n",
    "    self.reshape_convolution = lambda x: x.reshape(num_filters, -1)\n",
    "    self.relu = lambda x: F.relu(x).max(1).values\n",
    "    self.linear = torch.nn.Linear(num_filters, ntags)\n",
    "\n",
    "    self.layers = (\n",
    "      self.embedding,\n",
    "      self.reshape_embeddings,\n",
    "      self.convolution,\n",
    "      self.reshape_convolution,\n",
    "      self.relu,\n",
    "      self.linear\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return pipe(self.layers, x)\n",
    "\n",
    "model = CNN(nwords=n_words, emb_size=EMBEDDING_SIZE, ntags=n_class, num_filters=32, window_size=1)\n",
    "print(model)\n",
    "\n",
    "epochs = 15\n",
    "eta = 0.01\n",
    "optim = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "for i in range(epochs):\n",
    "  random.shuffle(train)\n",
    "\n",
    "  train_loss = 0.0\n",
    "  for (words, tag) in train:\n",
    "    pred = model(torch.tensor(words))\n",
    "    loss = F.cross_entropy(pred.view(1, -1), torch.tensor([tag]))\n",
    "    loss.backward()\n",
    "\n",
    "    train_loss += loss\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "  print(f\"iter {i!r}: avg. train loss={train_loss / len(train):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
